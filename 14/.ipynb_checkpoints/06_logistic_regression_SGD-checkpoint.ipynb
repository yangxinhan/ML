{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以梯度下降法求解羅吉斯迴歸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# 只取前兩個特徵，方便繪圖\n",
    "X = iris.data[:, :2]\n",
    "# 只取前兩個類別\n",
    "y = (iris.target != 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='b', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='r', label='1')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立羅吉斯迴歸類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # 加入偏差項(1)至X\n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    # 羅吉斯函數\n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # 損失函數\n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    # 以梯度下降法訓練模型\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # 權重初始值給 0\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        # 正向傳導與反向傳導\n",
    "        for i in range(self.num_iter):\n",
    "            # WX\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            # 梯度\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            # 更新權重\n",
    "            self.theta -= self.lr * gradient\n",
    "            \n",
    "            # 依據更新的權重計算損失\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            loss = self.__loss(h, y)\n",
    "            \n",
    "            # 列印損失\n",
    "            if(self.verbose ==True and i % 10000 == 0):\n",
    "                print(f'loss: {loss} \\t')\n",
    "    \n",
    "    # 預測機率\n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    # 預測\n",
    "    def predict(self, X):\n",
    "        return self.predict_prob(X).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(lr=0.1, num_iter=100000)\n",
    "\n",
    "%time model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "(preds == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 羅吉斯迴歸係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類結果繪圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='b', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='r', label='1')\n",
    "plt.legend()\n",
    "x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "probs = model.predict_prob(grid).reshape(xx1.shape)\n",
    "plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以 Scikit-learn 驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1e20)\n",
    "%time model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "(preds == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='b', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='r', label='1')\n",
    "plt.legend()\n",
    "x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "probs = model.predict_proba(grid)[:,1].reshape(xx1.shape)\n",
    "plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
